{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96a5bbbe-a5a6-450b-ad02-ba8fb30b6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5afbc96-a37e-4520-a2f0-c9c3ad8803bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
      "0         0           tcp  ftp_data   SF        491          0     0   \n",
      "1         0           udp     other   SF        146          0     0   \n",
      "2         0           tcp   private   S0          0          0     0   \n",
      "3         0           tcp      http   SF        232       8153     0   \n",
      "4         0           tcp      http   SF        199        420     0   \n",
      "\n",
      "   wrong_fragment  urgent  hot  num_failed_logins  logged_in  num_compromised  \\\n",
      "0               0       0    0                  0          0                0   \n",
      "1               0       0    0                  0          0                0   \n",
      "2               0       0    0                  0          0                0   \n",
      "3               0       0    0                  0          1                0   \n",
      "4               0       0    0                  0          1                0   \n",
      "\n",
      "   root_shell  su_attempted  num_root  num_file_creations  num_shells  \\\n",
      "0           0             0         0                   0           0   \n",
      "1           0             0         0                   0           0   \n",
      "2           0             0         0                   0           0   \n",
      "3           0             0         0                   0           0   \n",
      "4           0             0         0                   0           0   \n",
      "\n",
      "   num_access_files  num_outbound_cmds  is_host_login  is_guest_login  count  \\\n",
      "0                 0                  0              0               0      2   \n",
      "1                 0                  0              0               0     13   \n",
      "2                 0                  0              0               0    123   \n",
      "3                 0                  0              0               0      5   \n",
      "4                 0                  0              0               0     30   \n",
      "\n",
      "   srv_count  serror_rate  srv_serror_rate  rerror_rate  srv_rerror_rate  \\\n",
      "0          2          0.0              0.0          0.0              0.0   \n",
      "1          1          0.0              0.0          0.0              0.0   \n",
      "2          6          1.0              1.0          0.0              0.0   \n",
      "3          5          0.2              0.2          0.0              0.0   \n",
      "4         32          0.0              0.0          0.0              0.0   \n",
      "\n",
      "   same_srv_rate  diff_srv_rate  srv_diff_host_rate  dst_host_count  \\\n",
      "0           1.00           0.00                0.00             150   \n",
      "1           0.08           0.15                0.00             255   \n",
      "2           0.05           0.07                0.00             255   \n",
      "3           1.00           0.00                0.00              30   \n",
      "4           1.00           0.00                0.09             255   \n",
      "\n",
      "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0                  25                    0.17                    0.03   \n",
      "1                   1                    0.00                    0.60   \n",
      "2                  26                    0.10                    0.05   \n",
      "3                 255                    1.00                    0.00   \n",
      "4                 255                    1.00                    0.00   \n",
      "\n",
      "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0                         0.17                         0.00   \n",
      "1                         0.88                         0.00   \n",
      "2                         0.00                         0.00   \n",
      "3                         0.03                         0.04   \n",
      "4                         0.00                         0.00   \n",
      "\n",
      "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0                  0.00                      0.00                  0.05   \n",
      "1                  0.00                      0.00                  0.00   \n",
      "2                  1.00                      1.00                  0.00   \n",
      "3                  0.03                      0.01                  0.00   \n",
      "4                  0.00                      0.00                  0.00   \n",
      "\n",
      "   dst_host_srv_rerror_rate  outcome  level  \n",
      "0                      0.00   normal     20  \n",
      "1                      0.00   normal     15  \n",
      "2                      0.00  neptune     19  \n",
      "3                      0.01   normal     21  \n",
      "4                      0.00   normal     21  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the datasets\n",
    "data_train = pd.read_csv(\"/Users/sharathkarnati/Desktop/ml_codes/KDDTrain+.txt\", header=None)\n",
    "data_test = pd.read_csv(\"/Users/sharathkarnati/Desktop/ml_codes/KDDTest+.txt\", header=None)\n",
    "\n",
    "# Column names for the dataset\n",
    "columns = (['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot',\n",
    "            'num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations',\n",
    "            'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate',\n",
    "            'srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count',\n",
    "            'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate',\n",
    "            'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','outcome','level'])\n",
    "\n",
    "# Assign names to the columns\n",
    "data_train.columns = columns\n",
    "data_test.columns = columns\n",
    "\n",
    "# Check the data\n",
    "print(data_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f7421c-8664-41e5-b5b4-58611b122bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to scale numerical columns and encode categorical features\n",
    "def Scaling(df_num, cols):\n",
    "    std_scaler = RobustScaler()\n",
    "    std_scaler_temp = std_scaler.fit_transform(df_num)\n",
    "    std_df = pd.DataFrame(std_scaler_temp, columns=cols)\n",
    "    return std_df\n",
    "\n",
    "cat_cols = ['is_host_login','protocol_type','service','flag','land', 'logged_in','is_guest_login', 'level', 'outcome']\n",
    "\n",
    "def preprocess(dataframe):\n",
    "    df_num = dataframe.drop(cat_cols, axis=1)\n",
    "    num_cols = df_num.columns\n",
    "    scaled_df = Scaling(df_num, num_cols)\n",
    "    \n",
    "    dataframe.drop(labels=num_cols, axis=\"columns\", inplace=True)\n",
    "    dataframe[num_cols] = scaled_df[num_cols]\n",
    "    \n",
    "    dataframe.loc[dataframe['outcome'] == \"normal\", \"outcome\"] = 0\n",
    "    dataframe.loc[dataframe['outcome'] != 0, \"outcome\"] = 1\n",
    "    \n",
    "    dataframe = pd.get_dummies(dataframe, columns = ['protocol_type', 'service', 'flag'])\n",
    "    return dataframe\n",
    "\n",
    "# Preprocess both train and test data\n",
    "scaled_train = preprocess(data_train)\n",
    "scaled_test = preprocess(data_test)\n",
    "\n",
    "# Separate features and target variable\n",
    "x_train = scaled_train.drop(['outcome', 'level'], axis=1).values\n",
    "y_train = scaled_train['outcome'].values\n",
    "x_test = scaled_test.drop(['outcome', 'level'], axis=1).values\n",
    "y_test = scaled_test['outcome'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "586b5d18-7d03-4546-a390-ab3f2650f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dimensionality Reduction using PCA\n",
    "pca = PCA(n_components=20)\n",
    "x_train_reduced = pca.fit_transform(x_train)\n",
    "x_test_reduced = pca.transform(x_test)\n",
    "\n",
    "# Now the training and testing datasets are aligned and should work properly with PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14140110-0e74-46df-b101-866f788f1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split (not needed for PCA in this case as we already have x_train, x_test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "kernal_evals = {}\n",
    "\n",
    "# Evaluation function for classification models\n",
    "def evaluate_classification(model, name, X_train, X_test, y_train, y_test):\n",
    "    train_accuracy = metrics.accuracy_score(y_train, model.predict(X_train))\n",
    "    test_accuracy = metrics.accuracy_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    train_precision = metrics.precision_score(y_train, model.predict(X_train))\n",
    "    test_precision = metrics.precision_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    train_recall = metrics.recall_score(y_train, model.predict(X_train))\n",
    "    test_recall = metrics.recall_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    kernal_evals[name] = [train_accuracy, test_accuracy, train_precision, test_precision, train_recall, test_recall]\n",
    "    print(f\"Training Accuracy ({name}): {train_accuracy*100}%  Test Accuracy ({name}): {test_accuracy*100}%\")\n",
    "    print(f\"Training Precision ({name}): {train_precision*100}%  Test Precision ({name}): {test_precision*100}%\")\n",
    "    print(f\"Training Recall ({name}): {train_recall*100}%  Test Recall ({name}): {test_recall*100}%\")\n",
    "    \n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, model.predict(X_test))\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=['normal', 'attack'])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax.grid(False)\n",
    "    cm_display.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0407c04-10be-41a6-bafb-f3ecca5ddb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n",
      "Training Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     34515\n",
      "           1       0.96      0.96      0.96     29982\n",
      "\n",
      "    accuracy                           0.96     64497\n",
      "   macro avg       0.96      0.96      0.96     64497\n",
      "weighted avg       0.96      0.96      0.96     64497\n",
      "\n",
      "Test Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      8578\n",
      "           1       0.96      0.96      0.96      7547\n",
      "\n",
      "    accuracy                           0.96     16125\n",
      "   macro avg       0.96      0.96      0.96     16125\n",
      "weighted avg       0.96      0.96      0.96     16125\n",
      "\n",
      "Training Confusion Matrix for Logistic Regression:\n",
      "[[33436  1079]\n",
      " [ 1310 28672]]\n",
      "Test Confusion Matrix for Logistic Regression:\n",
      "[[8308  270]\n",
      " [ 328 7219]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Ensure target variable is properly encoded\n",
    "y_train = le.fit_transform(y_train)  # Encode labels in y_train\n",
    "y_test = le.transform(y_test)        # Apply the same encoding to y_test\n",
    "\n",
    "# Logistic Regression model\n",
    "lr = LogisticRegression(max_iter=1000)  # Increase iterations if needed\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_classification(model, model_name, x_train, x_test, y_train, y_test):\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    # Predictions on training and test data\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    print(f\"Training Classification Report for {model_name}:\")\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "    \n",
    "    print(f\"Test Classification Report for {model_name}:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    print(f\"Training Confusion Matrix for {model_name}:\")\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    \n",
    "    print(f\"Test Confusion Matrix for {model_name}:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Now call the evaluation function\n",
    "evaluate_classification(lr, \"Logistic Regression\", x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5ebcffd-1571-4985-96fd-11dcf1a7f469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (100, 5)\n",
      "y shape: (100,)\n",
      "x_train shape: (80, 5)\n",
      "y_train shape: (80,)\n",
      "Evaluating Logistic Regression...\n",
      "Training Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71        46\n",
      "           1       0.50      0.15      0.23        34\n",
      "\n",
      "    accuracy                           0.57        80\n",
      "   macro avg       0.54      0.52      0.47        80\n",
      "weighted avg       0.55      0.57      0.50        80\n",
      "\n",
      "Test Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.82      0.67        11\n",
      "           1       0.50      0.22      0.31         9\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.53      0.52      0.49        20\n",
      "weighted avg       0.53      0.55      0.51        20\n",
      "\n",
      "Training Confusion Matrix for Logistic Regression:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Confusion Matrix for Logistic Regression:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Example synthetic data (replace with your actual dataset)\n",
    "# Example: 100 samples, 5 features, binary classification labels\n",
    "x = np.random.rand(100, 5)  # 100 samples, 5 features\n",
    "y = np.random.randint(0, 2, 100)  # Binary classification (0 or 1)\n",
    "\n",
    "# Ensure x and y have consistent lengths\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure that x_train and y_train have the same length\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Ensure target variable is properly encoded\n",
    "y_train = le.fit_transform(y_train)  # Encode labels in y_train\n",
    "y_test = le.transform(y_test)        # Apply the same encoding to y_test\n",
    "\n",
    "# Logistic Regression model\n",
    "lr = LogisticRegression(max_iter=1000)  # Increase iterations if needed\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_classification(model, model_name, x_train, x_test, y_train, y_test):\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    # Predictions on training and test data\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    print(f\"Training Classification Report for {model_name}:\")\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "    \n",
    "    print(f\"Test Classification Report for {model_name}:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    print(f\"Training Confusion Matrix for {model_name}:\")\n",
    "    plot_confusion_matrix(y_train, y_train_pred, \"Training Confusion Matrix\")\n",
    "    \n",
    "    print(f\"Test Confusion Matrix for {model_name}:\")\n",
    "    plot_confusion_matrix(y_test, y_test_pred, \"Test Confusion Matrix\")\n",
    "    \n",
    "    # Optionally, you can add additional plots here for performance, anomalies, etc.\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "# Now call the evaluation function\n",
    "evaluate_classification(lr, \"Logistic Regression\", x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef811c2a-79c9-4022-9470-185509d06a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNeighbors Classifier...\n",
      "Training Classification Report for KNeighbors Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     34515\n",
      "           1       0.99      0.99      0.99     29982\n",
      "\n",
      "    accuracy                           0.99     64497\n",
      "   macro avg       0.99      0.99      0.99     64497\n",
      "weighted avg       0.99      0.99      0.99     64497\n",
      "\n",
      "Test Classification Report for KNeighbors Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      8578\n",
      "           1       0.99      0.99      0.99      7547\n",
      "\n",
      "    accuracy                           0.99     16125\n",
      "   macro avg       0.99      0.99      0.99     16125\n",
      "weighted avg       0.99      0.99      0.99     16125\n",
      "\n",
      "Training Confusion Matrix for KNeighbors Classifier:\n",
      "[[34243   272]\n",
      " [  428 29554]]\n",
      "Test Confusion Matrix for KNeighbors Classifier:\n",
      "[[8509   69]\n",
      " [ 108 7439]]\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=20).fit(x_train, y_train)\n",
    "evaluate_classification(knn, \"KNeighbors Classifier\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22705539-4644-4ab4-8e36-93926cd818a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Gaussian Naive Bayes...\n",
      "Training Classification Report for Gaussian Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     34515\n",
      "           1       0.94      0.90      0.92     29982\n",
      "\n",
      "    accuracy                           0.93     64497\n",
      "   macro avg       0.93      0.93      0.93     64497\n",
      "weighted avg       0.93      0.93      0.93     64497\n",
      "\n",
      "Test Classification Report for Gaussian Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94      8578\n",
      "           1       0.94      0.91      0.93      7547\n",
      "\n",
      "    accuracy                           0.93     16125\n",
      "   macro avg       0.93      0.93      0.93     16125\n",
      "weighted avg       0.93      0.93      0.93     16125\n",
      "\n",
      "Training Confusion Matrix for Gaussian Naive Bayes:\n",
      "[[32869  1646]\n",
      " [ 2854 27128]]\n",
      "Test Confusion Matrix for Gaussian Naive Bayes:\n",
      "[[8159  419]\n",
      " [ 666 6881]]\n"
     ]
    }
   ],
   "source": [
    " #Gaussian Naive Bayes\n",
    "gnb = GaussianNB().fit(x_train, y_train)\n",
    "evaluate_classification(gnb, \"Gaussian Naive Bayes\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7132441e-2679-40a2-8198-515f135e2da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear SVC...\n",
      "Training Classification Report for Linear SVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     34515\n",
      "           1       0.99      0.95      0.97     29982\n",
      "\n",
      "    accuracy                           0.97     64497\n",
      "   macro avg       0.97      0.97      0.97     64497\n",
      "weighted avg       0.97      0.97      0.97     64497\n",
      "\n",
      "Test Classification Report for Linear SVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      8578\n",
      "           1       0.99      0.95      0.97      7547\n",
      "\n",
      "    accuracy                           0.97     16125\n",
      "   macro avg       0.97      0.97      0.97     16125\n",
      "weighted avg       0.97      0.97      0.97     16125\n",
      "\n",
      "Training Confusion Matrix for Linear SVC:\n",
      "[[34118   397]\n",
      " [ 1557 28425]]\n",
      "Test Confusion Matrix for Linear SVC:\n",
      "[[8482   96]\n",
      " [ 383 7164]]\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Classifier\n",
    "lin_svc = svm.LinearSVC().fit(x_train, y_train)\n",
    "evaluate_classification(lin_svc, \"Linear SVC\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b27479ca-3920-4ce4-b595-d9255735d1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree Classifier...\n",
      "Training Classification Report for Decision Tree Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     34515\n",
      "           1       1.00      1.00      1.00     29982\n",
      "\n",
      "    accuracy                           1.00     64497\n",
      "   macro avg       1.00      1.00      1.00     64497\n",
      "weighted avg       1.00      1.00      1.00     64497\n",
      "\n",
      "Test Classification Report for Decision Tree Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8578\n",
      "           1       1.00      1.00      1.00      7547\n",
      "\n",
      "    accuracy                           1.00     16125\n",
      "   macro avg       1.00      1.00      1.00     16125\n",
      "weighted avg       1.00      1.00      1.00     16125\n",
      "\n",
      "Training Confusion Matrix for Decision Tree Classifier:\n",
      "[[34515     0]\n",
      " [    1 29981]]\n",
      "Test Confusion Matrix for Decision Tree Classifier:\n",
      "[[8560   18]\n",
      " [  28 7519]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(max_depth=3).fit(x_train, y_train)\n",
    "tdt = DecisionTreeClassifier().fit(x_train, y_train)\n",
    "evaluate_classification(tdt, \"Decision Tree Classifier\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92085d80-6b1d-4434-b4c0-3a52bb56bfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest Classifier...\n",
      "Training Classification Report for Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     34515\n",
      "           1       1.00      1.00      1.00     29982\n",
      "\n",
      "    accuracy                           1.00     64497\n",
      "   macro avg       1.00      1.00      1.00     64497\n",
      "weighted avg       1.00      1.00      1.00     64497\n",
      "\n",
      "Test Classification Report for Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8578\n",
      "           1       1.00      1.00      1.00      7547\n",
      "\n",
      "    accuracy                           1.00     16125\n",
      "   macro avg       1.00      1.00      1.00     16125\n",
      "weighted avg       1.00      1.00      1.00     16125\n",
      "\n",
      "Training Confusion Matrix for Random Forest Classifier:\n",
      "[[34514     1]\n",
      " [    0 29982]]\n",
      "Test Confusion Matrix for Random Forest Classifier:\n",
      "[[8572    6]\n",
      " [  16 7531]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier().fit(x_train, y_train)\n",
    "evaluate_classification(rf, \"Random Forest Classifier\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfb84067-21fa-4a20-84a9-7b0e7d74b4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error (XGBoost): 0.037001454112249976  Test Error (XGBoost): 0.051564495831481996\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Regressor (for Regression Task)\n",
    "xg_r = xgb.XGBRegressor(objective ='reg:linear', n_estimators=20).fit(x_train, y_train)\n",
    "train_error = metrics.mean_squared_error(y_train, xg_r.predict(x_train), squared=False)\n",
    "test_error = metrics.mean_squared_error(y_test, xg_r.predict(x_test), squared=False)\n",
    "print(f\"Training Error (XGBoost): {train_error}  Test Error (XGBoost): {test_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfea883c-2ede-494c-b0d8-b663105177d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in training data: 43\n",
      "Number of columns in testing data: 43\n",
      "Classification Report for Random Forest with PCA (Training Data):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        66\n",
      "           1       1.00      1.00      1.00        62\n",
      "           2       1.00      1.00      1.00        54\n",
      "           3       1.00      1.00      1.00        65\n",
      "           4       1.00      1.00      1.00        79\n",
      "           5       1.00      1.00      1.00        81\n",
      "           6       1.00      1.00      1.00        96\n",
      "           7       1.00      1.00      1.00       118\n",
      "           8       1.00      1.00      1.00       106\n",
      "           9       1.00      1.00      1.00       194\n",
      "          10       1.00      1.00      1.00       253\n",
      "          11       1.00      1.00      1.00       641\n",
      "          12       1.00      1.00      1.00       729\n",
      "          13       1.00      1.00      1.00       451\n",
      "          14       1.00      1.00      1.00       674\n",
      "          15       1.00      1.00      1.00      3990\n",
      "          16       1.00      1.00      1.00      2393\n",
      "          17       1.00      1.00      1.00      3074\n",
      "          18       1.00      1.00      1.00     20667\n",
      "          19       1.00      1.00      1.00     10284\n",
      "          20       1.00      1.00      1.00     19339\n",
      "          21       1.00      1.00      1.00     62557\n",
      "\n",
      "    accuracy                           1.00    125973\n",
      "   macro avg       1.00      1.00      1.00    125973\n",
      "weighted avg       1.00      1.00      1.00    125973\n",
      "\n",
      "Classification Report for Random Forest with PCA (Test Data):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       123\n",
      "           1       0.10      0.01      0.02        87\n",
      "           2       0.10      0.02      0.03        55\n",
      "           3       0.33      0.01      0.02       116\n",
      "           4       0.33      0.01      0.02       101\n",
      "           5       0.00      0.00      0.00       103\n",
      "           6       0.06      0.01      0.01       157\n",
      "           7       0.17      0.02      0.03       249\n",
      "           8       0.02      0.01      0.01       131\n",
      "           9       0.02      0.01      0.01       106\n",
      "          10       0.11      0.06      0.08       195\n",
      "          11       0.19      0.06      0.09       461\n",
      "          12       0.17      0.08      0.11       486\n",
      "          13       0.14      0.01      0.02       519\n",
      "          14       0.09      0.04      0.05       736\n",
      "          15       0.31      0.15      0.20      1176\n",
      "          16       0.54      0.15      0.23       681\n",
      "          17       0.23      0.12      0.16      1168\n",
      "          18       0.52      0.51      0.51      2967\n",
      "          19       0.42      0.39      0.40       890\n",
      "          20       0.28      0.65      0.39      1343\n",
      "          21       0.76      0.95      0.84     10694\n",
      "\n",
      "    accuracy                           0.59     22544\n",
      "   macro avg       0.22      0.15      0.15     22544\n",
      "weighted avg       0.53      0.59      0.54     22544\n",
      "\n",
      "Confusion Matrix for Random Forest with PCA (Test Data):\n",
      "\n",
      "[[    0     1     2     0     0     0     0     0     0     0     0     0\n",
      "      1     0     1     3     0     4    11     2    45    53]\n",
      " [    0     1     2     0     0     0     0     0     0     0     1     0\n",
      "      0     1     1     2     0     8     7     2    55     7]\n",
      " [    0     0     1     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     1     1     2     6    29    15]\n",
      " [    1     1     0     1     0     0     0     0     0     0     2     0\n",
      "      0     1     7    15     0     5    28     5    46     4]\n",
      " [    0     0     0     0     1     0     0     0     0     1     0     0\n",
      "      0     0     2     0     2    15    26     7    36    11]\n",
      " [    0     1     0     0     2     0     0     2     0     0     3     1\n",
      "      1     0     0     8     5    19    22     7    20    12]\n",
      " [    0     1     0     0     0     0     1     2     0     0     3     0\n",
      "      6     1     1    19     4    15    11     1    20    72]\n",
      " [    0     0     0     0     0     0     4     4     1     0     2     2\n",
      "      4     1     5    22     0    13    18     4    52   117]\n",
      " [    0     0     0     2     0     0     0     0     1     2     2     1\n",
      "      6     2     0    37     4     5     4     1    26    38]\n",
      " [    0     1     0     0     0     0     0     0     1     1     2     2\n",
      "      7     2     5     2     1     4     6     1    39    32]\n",
      " [    0     1     0     0     0     1     0     0     2     1    12     2\n",
      "      6     0     4     7     0     1     4     1    47   106]\n",
      " [    0     1     0     0     0     0     0     2     1     2     9    28\n",
      "     30     0     8    11     1    25     7     1   172   163]\n",
      " [    0     1     1     0     0     0     1     1     1     2    14    32\n",
      "     39     1    12    38     3    37    13     1   152   137]\n",
      " [    0     0     0     0     0     0     7     1     7    10     2    29\n",
      "     17     6    39    25     6    39    34     4   127   166]\n",
      " [    0     0     0     0     0     1     1     3     8     2     7    14\n",
      "     16    12    28    41    12    34    57     8   159   333]\n",
      " [    0     0     0     0     0     0     0     2     4     8    14    32\n",
      "     18     3    28   173    29    44   124     5   152   540]\n",
      " [    0     0     0     0     0     2     1     1    13     4    26     3\n",
      "      6     0    15    78   102    26    80    19    73   232]\n",
      " [    0     0     0     0     0     0     2     0     3     2     9     0\n",
      "     14     1    19    53     8   145   609    30    70   203]\n",
      " [    0     1     1     0     0     0     1     5     6     7     2     0\n",
      "     23     3    96    22    12   115  1505   157   363   648]\n",
      " [    0     0     0     0     0     0     0     0     0     0     4     0\n",
      "     28     5    42     0     0    49   122   344   210    86]\n",
      " [    0     0     0     0     0     0     0     1     0     2     0     2\n",
      "      1     3     1     1     0    15   104   122   874   217]\n",
      " [    1     0     3     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     6   116    82   367 10118]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the datasets\n",
    "data_train = pd.read_csv(\"/Users/sharathkarnati/Desktop/ml_codes/KDDTrain+.txt\", header=None)\n",
    "data_test = pd.read_csv(\"/Users/sharathkarnati/Desktop/ml_codes/KDDTest+.txt\", header=None)\n",
    "# Check the number of columns in both training and testing datasets\n",
    "print(f\"Number of columns in training data: {data_train.shape[1]}\")\n",
    "print(f\"Number of columns in testing data: {data_test.shape[1]}\")\n",
    "\n",
    "column_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \n",
    "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\", \n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\", \n",
    "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \n",
    "    \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \n",
    "    \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \n",
    "    \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\", \n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \n",
    "    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\", \n",
    "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \n",
    "    \"dst_host_srv_rerror_rate\", \"extra_column\", \"class\"\n",
    "]\n",
    "\n",
    "\n",
    "# Assign column names to the datasets\n",
    "data_train.columns = column_names\n",
    "data_test.columns = column_names\n",
    "\n",
    "# Combine train and test data to ensure consistent dummy variable columns\n",
    "data_combined = pd.concat([data_train, data_test], axis=0)\n",
    "\n",
    "# Define 'X' as the feature matrix and 'y' as the target variable\n",
    "X_combined = data_combined.drop(columns=['class'])\n",
    "y_combined = data_combined['class']\n",
    "\n",
    "# Convert categorical features into numeric values using pd.get_dummies\n",
    "X_combined = pd.get_dummies(X_combined)\n",
    "\n",
    "# Split the combined data back into train and test sets\n",
    "X_train = X_combined.iloc[:len(data_train), :]\n",
    "X_test = X_combined.iloc[len(data_train):, :]\n",
    "y_train = y_combined.iloc[:len(data_train)]\n",
    "y_test = y_combined.iloc[len(data_train):]\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=10)  # Adjust the number of components to your needs\n",
    "X_train_reduced = pca.fit_transform(X_train)  # Fit and transform on the training data\n",
    "X_test_reduced = pca.transform(X_test)  # Only transform on the test data\n",
    "\n",
    "# Train Random Forest Classifier with the reduced training data\n",
    "rrf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rrf.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_classification(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    # Predict on the training and test sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Print classification report for both train and test sets\n",
    "    print(f\"Classification Report for {model_name} (Training Data):\\n\")\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "    \n",
    "    print(f\"Classification Report for {model_name} (Test Data):\\n\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    # Print confusion matrix for test data\n",
    "    print(f\"Confusion Matrix for {model_name} (Test Data):\\n\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Call the evaluation function\n",
    "evaluate_classification(rrf, \"Random Forest with PCA\", X_train_reduced, X_test_reduced, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f6e4e9a-084f-47be-b711-bee410fc58a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in data_train: 43\n",
      "Number of columns in data_test: 43\n",
      "Epoch 1/100\n",
      "247/247 - 1s - 5ms/step - accuracy: 4.6835e-04 - loss: 65223778304.0000\n",
      "Epoch 2/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.8423e-04 - loss: 38363193344.0000\n",
      "Epoch 3/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 5.0011e-04 - loss: 26514864128.0000\n",
      "Epoch 4/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.7629e-04 - loss: 21062860800.0000\n",
      "Epoch 5/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.8423e-04 - loss: 12999608320.0000\n",
      "Epoch 6/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.8423e-04 - loss: 9583443968.0000\n",
      "Epoch 7/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 6315628032.0000\n",
      "Epoch 8/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 4233739264.0000\n",
      "Epoch 9/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.8423e-04 - loss: 2849927168.0000\n",
      "Epoch 10/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.8423e-04 - loss: 1951836160.0000\n",
      "Epoch 11/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 1152221312.0000\n",
      "Epoch 12/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 649215936.0000\n",
      "Epoch 13/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 349796960.0000\n",
      "Epoch 14/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 212270208.0000\n",
      "Epoch 15/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 27116115968.0000\n",
      "Epoch 16/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 2088841984.0000\n",
      "Epoch 17/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 1677277184.0000\n",
      "Epoch 18/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 1455711744.0000\n",
      "Epoch 19/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.8423e-04 - loss: 1472444672.0000\n",
      "Epoch 20/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 1479352448.0000\n",
      "Epoch 21/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 1024875520.0000\n",
      "Epoch 22/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 923423040.0000\n",
      "Epoch 23/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 1615978880.0000\n",
      "Epoch 24/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 938687680.0000\n",
      "Epoch 25/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 816243840.0000\n",
      "Epoch 26/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 658651136.0000\n",
      "Epoch 27/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 581785600.0000\n",
      "Epoch 28/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 905278336.0000\n",
      "Epoch 29/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 1343829888.0000\n",
      "Epoch 30/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 790707072.0000\n",
      "Epoch 31/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 616995776.0000\n",
      "Epoch 32/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 476888480.0000\n",
      "Epoch 33/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 1307598208.0000\n",
      "Epoch 34/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 522387520.0000\n",
      "Epoch 35/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 367949792.0000\n",
      "Epoch 36/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 327589504.0000\n",
      "Epoch 37/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 334064512.0000\n",
      "Epoch 38/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 605926336.0000\n",
      "Epoch 39/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 278437856.0000\n",
      "Epoch 40/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 151657440.0000\n",
      "Epoch 41/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 366468672.0000\n",
      "Epoch 42/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 263903936.0000\n",
      "Epoch 43/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 219475312.0000\n",
      "Epoch 44/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 52759572.0000\n",
      "Epoch 45/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: -2.2681e+07\n",
      "Epoch 46/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 404317.1562\n",
      "Epoch 47/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 5048886272.0000\n",
      "Epoch 48/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 385618848.0000\n",
      "Epoch 49/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 1898506.3750\n",
      "Epoch 50/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: -1.5605e+07\n",
      "Epoch 51/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: -4.6922e+07\n",
      "Epoch 52/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: -2.3364e+07\n",
      "Epoch 53/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 56640376.0000\n",
      "Epoch 54/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 1037377792.0000\n",
      "Epoch 55/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 413694336.0000\n",
      "Epoch 56/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 380394720.0000\n",
      "Epoch 57/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 258583296.0000\n",
      "Epoch 58/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 4009261824.0000\n",
      "Epoch 59/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 30937663488.0000\n",
      "Epoch 60/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 566144064.0000\n",
      "Epoch 61/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 1963461248.0000\n",
      "Epoch 62/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 493324896.0000\n",
      "Epoch 63/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 1252587776.0000\n",
      "Epoch 64/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 753111680.0000\n",
      "Epoch 65/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 520638176.0000\n",
      "Epoch 66/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 1076167680.0000\n",
      "Epoch 67/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 1672694784.0000\n",
      "Epoch 68/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 866886144.0000\n",
      "Epoch 69/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 559860288.0000\n",
      "Epoch 70/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 776404736.0000\n",
      "Epoch 71/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 359316096.0000\n",
      "Epoch 72/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 176118544.0000\n",
      "Epoch 73/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 9517422592.0000\n",
      "Epoch 74/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 1485506432.0000\n",
      "Epoch 75/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 84856635392.0000\n",
      "Epoch 76/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: -2.7865e+08\n",
      "Epoch 77/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: -3.1592e+08\n",
      "Epoch 78/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 3081512192.0000\n",
      "Epoch 79/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 208680256.0000\n",
      "Epoch 80/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 200654224.0000\n",
      "Epoch 81/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 1221038720.0000\n",
      "Epoch 82/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 1640918400.0000\n",
      "Epoch 83/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: -2.4463e+07\n",
      "Epoch 84/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 1538769920.0000\n",
      "Epoch 85/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: -2.1001e+08\n",
      "Epoch 86/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: -5.5582e+07\n",
      "Epoch 87/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: -2.7515e+08\n",
      "Epoch 88/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: -3.7500e+08\n",
      "Epoch 89/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: -1.0287e+08\n",
      "Epoch 90/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: -1.1311e+08\n",
      "Epoch 91/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: -4.7773e+08\n",
      "Epoch 92/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: -5.5663e+08\n",
      "Epoch 93/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: -5.9568e+08\n",
      "Epoch 94/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: -5.2601e+08\n",
      "Epoch 95/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: -6.9549e+08\n",
      "Epoch 96/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: 23692142592.0000\n",
      "Epoch 97/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 54189703168.0000\n",
      "Epoch 98/100\n",
      "247/247 - 1s - 4ms/step - accuracy: 4.9217e-04 - loss: -2.4626e+08\n",
      "Epoch 99/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: -2.8493e+08\n",
      "Epoch 100/100\n",
      "247/247 - 1s - 3ms/step - accuracy: 4.9217e-04 - loss: 109805232.0000\n",
      "Training Accuracy (Neural Network): 0.04921689396724105%  Test Accuracy (Neural Network): 0.38591199554502964%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the datasets\n",
    "data_train = pd.read_csv(\"/Users/sharathkarnati/Desktop/ml_codes/KDDTrain+.txt\", header=None)\n",
    "data_test = pd.read_csv(\"/Users/sharathkarnati/Desktop/ml_codes/KDDTest+.txt\", header=None)\n",
    "\n",
    "# Check the number of columns in each dataset\n",
    "print(f\"Number of columns in data_train: {data_train.shape[1]}\")\n",
    "print(f\"Number of columns in data_test: {data_test.shape[1]}\")\n",
    "\n",
    "# Define the column names based on the dataset description\n",
    "column_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \n",
    "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\", \n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\", \n",
    "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \n",
    "    \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \n",
    "    \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \n",
    "    \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\", \n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \n",
    "    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\", \n",
    "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \n",
    "    \"dst_host_srv_rerror_rate\", \"class\"\n",
    "]\n",
    "\n",
    "# If the datasets have an extra column (like an index column), remove it\n",
    "data_train = data_train.iloc[:, 1:]  # Remove the first column if it's an index\n",
    "data_test = data_test.iloc[:, 1:]  # Remove the first column if it's an index\n",
    "\n",
    "# Assign column names to the datasets\n",
    "data_train.columns = column_names\n",
    "data_test.columns = column_names\n",
    "\n",
    "# Define 'X' as the feature matrix and 'y' as the target variable\n",
    "X_train = data_train.drop(columns=['class'])\n",
    "y_train = data_train['class']\n",
    "\n",
    "X_test = data_test.drop(columns=['class'])\n",
    "y_test = data_test['class']\n",
    "\n",
    "# Convert categorical features into numeric values (e.g., protocol_type, service, flag)\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "# Ensure the feature matrices have the same shape by aligning the columns\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Neural Network Model (Deep Learning)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu', input_shape=(X_train.shape[1],), \n",
    "                          kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4), \n",
    "                          bias_regularizer=regularizers.L2(1e-4),\n",
    "                          activity_regularizer=regularizers.L2(1e-5)),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu', \n",
    "                          kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4), \n",
    "                          bias_regularizer=regularizers.L2(1e-4),\n",
    "                          activity_regularizer=regularizers.L2(1e-5)),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(units=512, activation='relu', \n",
    "                          kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4), \n",
    "                          bias_regularizer=regularizers.L2(1e-4),\n",
    "                          activity_regularizer=regularizers.L2(1e-5)),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu', \n",
    "                          kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4), \n",
    "                          bias_regularizer=regularizers.L2(1e-4),\n",
    "                          activity_regularizer=regularizers.L2(1e-5)),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=512, epochs=100, verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print results\n",
    "print(f\"Training Accuracy (Neural Network): {train_acc*100}%  Test Accuracy (Neural Network): {test_acc*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0d6de-eae2-42c9-8df5-f9f518cbc4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd12f437-0ca2-41af-8049-bbefd33f1ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e943bb3e-5b1e-4dbf-959c-491ba3af9f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
